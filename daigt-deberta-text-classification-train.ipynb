{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":61542,"databundleVersionId":6888007,"sourceType":"competition"},{"sourceId":6847931,"sourceType":"datasetVersion","datasetId":3936750}],"dockerImageVersionId":30559,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import ast\nimport copy\nimport gc\nimport itertools\nimport joblib\nimport json\nimport math\nimport matplotlib.pyplot as plt\nimport multiprocessing\nimport numpy as np\nimport os\nimport pandas as pd\nimport pickle\nimport random\nimport re\nimport scipy as sp\nimport string\nimport sys\nimport time\nimport warnings\n\n\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\nimport torch\nimport torch.nn as nn\nfrom torch.nn import Parameter\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD, AdamW\nfrom torch.optim.lr_scheduler import OneCycleLR\nfrom torch.utils.data import DataLoader, Dataset\nfrom tqdm.auto import tqdm\n\n# ======= OPTIONS =========\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Current device is: {device}\")\nwarnings.filterwarnings(\"ignore\")\n!mkdir output","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-12-28T17:24:08.952841Z","iopub.execute_input":"2023-12-28T17:24:08.953812Z","iopub.status.idle":"2023-12-28T17:24:12.175289Z","shell.execute_reply.started":"2023-12-28T17:24:08.953772Z","shell.execute_reply":"2023-12-28T17:24:12.174152Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"name":"stdout","text":"Current device is: cuda\nmkdir: cannot create directory ‘output’: File exists\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### <b><span style='color:#F1A424'>Tokenizers and transformers</span></b>","metadata":{}},{"cell_type":"code","source":"import tokenizers\nimport transformers\nfrom transformers import AutoTokenizer, AutoModel, AutoConfig\nfrom transformers import DistilBertModel, DistilBertConfig\n\nfrom transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n%env TOKENIZERS_PARALLELISM=true\nprint(f\"tokenizers.__version__: {tokenizers.__version__}\")\nprint(f\"transformers.__version__: {transformers.__version__}\")","metadata":{"_kg_hide-input":true,"scrolled":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-12-28T17:24:12.177827Z","iopub.execute_input":"2023-12-28T17:24:12.178633Z","iopub.status.idle":"2023-12-28T17:24:16.294157Z","shell.execute_reply.started":"2023-12-28T17:24:12.178596Z","shell.execute_reply":"2023-12-28T17:24:16.293229Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"env: TOKENIZERS_PARALLELISM=true\ntokenizers.__version__: 0.13.3\ntransformers.__version__: 4.33.0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# <b><span style='color:#F1A424'>|</span> Configuration</b><a class='anchor' id='configuration'></a> [↑](#top) \n\n***\n\nCentral repository for this notebook's hyperparameters.","metadata":{"papermill":{"duration":0.006569,"end_time":"2022-08-31T07:01:57.395826","exception":false,"start_time":"2022-08-31T07:01:57.389257","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class config:\n    APEX = True # Automatic Precision Enabled\n    BATCH_SCHEDULER = True\n    BATCH_SIZE_TRAIN = 64\n    BATCH_SIZE_VALID = 32\n    BETAS = (0.9, 0.999)\n    DEBUG = False\n    DECODER_LR = 2e-5\n    ENCODER_LR = 2e-5\n    EPOCHS = 5\n    EPS = 1e-6\n    FOLDS = 4\n    GRADIENT_ACCUMULATION_STEPS = 1\n    GRADIENT_CHECKPOINTING = True\n    MAX_GRAD_NORM=1000\n    MAX_LEN = 512\n    MIN_LR = 1e-6\n    MODEL = \"distilbert-base-uncased\"\n    NUM_CYCLES = 0.5\n    NUM_WARMUP_STEPS = 0\n    NUM_WORKERS = multiprocessing.cpu_count()\n    PRINT_FREQ = 20\n    SCHEDULER = 'cosine' # ['linear', 'cosine']\n    SEED = 27\n    TRAIN = True\n    TRAIN_FOLDS = [0, 1, 2, 3]\n    \n    WEIGHT_DECAY = 0.01\n\n    \nclass paths:\n    OUTPUT_DIR = \"/kaggle/working/output\"\n    EXTERNAL_DATA = \"/kaggle/input/daigt-external-dataset/daigt_external_dataset.csv\"\n    TRAIN_PROMPTS = \"/kaggle/input/llm-detect-ai-generated-text/train_prompts.csv\"\n    TRAIN_ESSAYS = \"/kaggle/input/llm-detect-ai-generated-text/train_essays.csv\"\n    TEST_ESSAYS = \"/kaggle/input/llm-detect-ai-generated-text/test_essays.csv\"\n    \n\nif config.DEBUG:\n    config.EPOCHS = 2","metadata":{"papermill":{"duration":0.015868,"end_time":"2022-08-31T07:01:57.417077","exception":false,"start_time":"2022-08-31T07:01:57.401209","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-28T17:24:16.295189Z","iopub.execute_input":"2023-12-28T17:24:16.295482Z","iopub.status.idle":"2023-12-28T17:24:16.305532Z","shell.execute_reply.started":"2023-12-28T17:24:16.295457Z","shell.execute_reply":"2023-12-28T17:24:16.304656Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# <b><span style='color:#F1A424'>|</span> Utils</b><a class='anchor' id='utils'></a> [↑](#top) \n\n***\n\nUtility functions used throughout the notebook.","metadata":{"papermill":{"duration":0.007998,"end_time":"2022-08-31T07:03:04.079768","exception":false,"start_time":"2022-08-31T07:03:04.07177","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def get_config_dict(config):\n    \"\"\"\n    Return the config, which is originally a class, as a Python dictionary.\n    \"\"\"\n    config_dict = dict((key, value) for key, value in config.__dict__.items() \n    if not callable(value) and not key.startswith('__'))\n    return config_dict\n\n\ndef get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n    param_optimizer = list(model.named_parameters())\n    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n    optimizer_parameters = [\n        {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)],\n         'lr': encoder_lr, 'weight_decay': weight_decay},\n        {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)],\n         'lr': encoder_lr, 'weight_decay': 0.0},\n        {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n         'lr': decoder_lr, 'weight_decay': 0.0}\n    ]\n    return optimizer_parameters\n\n\ndef get_logger(filename=paths.OUTPUT_DIR):\n    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=f\"{filename}.log\")\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    return logger\n\n\ndef get_scheduler(cfg, optimizer, num_train_steps):\n    if cfg.SCHEDULER == 'linear':\n        scheduler = get_linear_schedule_with_warmup(\n            optimizer, num_warmup_steps=cfg.NUM_WARMUP_STEPS,\n            num_training_steps=num_train_steps\n        )\n    elif cfg.SCHEDULER == 'cosine':\n        scheduler = get_cosine_schedule_with_warmup(\n            optimizer, num_warmup_steps=cfg.NUM_WARMUP_STEPS,\n            num_training_steps=num_train_steps, num_cycles=cfg.NUM_CYCLES\n        )\n    return scheduler\n    \n\ndef get_score(y_trues, y_preds):\n    score = roc_auc_score(y_trues, y_preds)\n    return score\n\n\ndef seed_everything(seed=20):\n    \"\"\"Seed everything to ensure reproducibility\"\"\"\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    \n\ndef sep():\n    print(\"-\"*100)\n    \n    \ndef sigmoid(x):\n    return 1 / (1 + np.exp(-x))  \n    \nLOGGER = get_logger()\nseed_everything(seed=config.SEED)","metadata":{"papermill":{"duration":0.024132,"end_time":"2022-08-31T07:03:04.111108","exception":false,"start_time":"2022-08-31T07:03:04.086976","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-28T17:24:16.307534Z","iopub.execute_input":"2023-12-28T17:24:16.307876Z","iopub.status.idle":"2023-12-28T17:24:16.325856Z","shell.execute_reply.started":"2023-12-28T17:24:16.307844Z","shell.execute_reply":"2023-12-28T17:24:16.324876Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# <b><span style='color:#F1A424'>|</span> Load Data</b><a class='anchor' id='load_data'></a> [↑](#top) \n\n***\n\nLoad data.","metadata":{"papermill":{"duration":0.012589,"end_time":"2022-08-31T07:03:04.13341","exception":false,"start_time":"2022-08-31T07:03:04.120821","status":"completed"},"tags":[]}},{"cell_type":"code","source":"train_df = pd.read_csv(paths.TRAIN_ESSAYS, sep=',')\nexternal_df = pd.read_csv(paths.EXTERNAL_DATA, sep=',')\ntrain_prompts = pd.read_csv(paths.TRAIN_PROMPTS, sep=',')\nprint(f\"Train essays dataframe has shape: {train_df.shape}\"), sep()\nprint(f\"External essays dataframe has shape: {external_df.shape}\"), sep()\nprint(f\"Train prompts dataframe has shape: {train_prompts.shape}\"), sep()\ndisplay(train_df.head())\ndisplay(external_df.head())\ndisplay(train_prompts.head())","metadata":{"papermill":{"duration":0.242687,"end_time":"2022-08-31T07:03:04.383434","exception":false,"start_time":"2022-08-31T07:03:04.140747","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-28T17:24:16.328817Z","iopub.execute_input":"2023-12-28T17:24:16.329113Z","iopub.status.idle":"2023-12-28T17:24:16.510350Z","shell.execute_reply.started":"2023-12-28T17:24:16.329086Z","shell.execute_reply":"2023-12-28T17:24:16.509403Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Train essays dataframe has shape: (1378, 4)\n----------------------------------------------------------------------------------------------------\nExternal essays dataframe has shape: (2421, 4)\n----------------------------------------------------------------------------------------------------\nTrain prompts dataframe has shape: (2, 4)\n----------------------------------------------------------------------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"         id  prompt_id                                               text  generated\n0  0059830c          0  Cars. Cars have been around since they became ...          0\n1  005db917          0  Transportation is a large necessity in most co...          0\n2  008f63e3          0  \"America's love affair with it's vehicles seem...          0\n3  00940276          0  How often do you ride in a car? Do you drive a...          0\n4  00c39458          0  Cars are a wonderful thing. They are perhaps o...          0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>prompt_id</th>\n      <th>text</th>\n      <th>generated</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0059830c</td>\n      <td>0</td>\n      <td>Cars. Cars have been around since they became ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>005db917</td>\n      <td>0</td>\n      <td>Transportation is a large necessity in most co...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>008f63e3</td>\n      <td>0</td>\n      <td>\"America's love affair with it's vehicles seem...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00940276</td>\n      <td>0</td>\n      <td>How often do you ride in a car? Do you drive a...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00c39458</td>\n      <td>0</td>\n      <td>Cars are a wonderful thing. They are perhaps o...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"             id                                               text                                       instructions                                        source_text\n0  6060D28C05B6  Some schools in United States ofter classes fr...  \\nTask: Write a persuasive essay on whether or...  \\nWhen considering the pros and cons of attend...\n1  60623DB5DE7A  Four-day work week, a remarkable idea to conse...  \\nTask: Research the advantages and disadvanta...  \\nOne of the primary arguments for implementin...\n2  607A39D981DE  Students and their families should consider an...  \\nTask: \\n\\n1. Talk to your parents before tak...  \\nBefore making any decisions about getting in...\n3  60ACDFA1609E  Agree you will never grow if something beyond ...  \\nTask: Write an essay discussing the benefits...  \\nRalph Waldo Emerson once said, \"Go confident...\n4  60AE13D3F07B  I think our character traits are formed by inf...  \\nTask: Research and discuss how character tra...  \\nHuman character traits are shaped by a wide ...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n      <th>instructions</th>\n      <th>source_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6060D28C05B6</td>\n      <td>Some schools in United States ofter classes fr...</td>\n      <td>\\nTask: Write a persuasive essay on whether or...</td>\n      <td>\\nWhen considering the pros and cons of attend...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>60623DB5DE7A</td>\n      <td>Four-day work week, a remarkable idea to conse...</td>\n      <td>\\nTask: Research the advantages and disadvanta...</td>\n      <td>\\nOne of the primary arguments for implementin...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>607A39D981DE</td>\n      <td>Students and their families should consider an...</td>\n      <td>\\nTask: \\n\\n1. Talk to your parents before tak...</td>\n      <td>\\nBefore making any decisions about getting in...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>60ACDFA1609E</td>\n      <td>Agree you will never grow if something beyond ...</td>\n      <td>\\nTask: Write an essay discussing the benefits...</td>\n      <td>\\nRalph Waldo Emerson once said, \"Go confident...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>60AE13D3F07B</td>\n      <td>I think our character traits are formed by inf...</td>\n      <td>\\nTask: Research and discuss how character tra...</td>\n      <td>\\nHuman character traits are shaped by a wide ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"   prompt_id                       prompt_name                                       instructions                                        source_text\n0          0                   Car-free cities  Write an explanatory essay to inform fellow ci...  # In German Suburb, Life Goes On Without Cars ...\n1          1  Does the electoral college work?  Write a letter to your state senator in which ...  # What Is the Electoral College? by the Office...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt_id</th>\n      <th>prompt_name</th>\n      <th>instructions</th>\n      <th>source_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Car-free cities</td>\n      <td>Write an explanatory essay to inform fellow ci...</td>\n      <td># In German Suburb, Life Goes On Without Cars ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Does the electoral college work?</td>\n      <td>Write a letter to your state senator in which ...</td>\n      <td># What Is the Electoral College? by the Office...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### <b><span style='color:#F1A424'>Add External Data</span></b>\n\nWe will use the external data to train our model:\n- `source_text` is AI-generated\n- `text` is student-written texts from FeedBack prize 3 competition.","metadata":{}},{"cell_type":"code","source":"external_df1 = external_df[[\"id\", \"source_text\"]]\nexternal_df1.columns = [\"id\", \"text\"]\nexternal_df1['text'] = external_df['text'].str.replace('\\n', '')\nexternal_df1[\"generated\"] = 1\nexternal_df2 = external_df[[\"id\", \"text\"]]\nexternal_df2[\"generated\"] = 0\n\ntrain_df.drop(columns=[\"prompt_id\"],inplace=True)\ntrain_df = pd.concat([train_df, external_df1, external_df2])\ntrain_df.reset_index(inplace=True, drop=True)\nprint(f\"Train dataframe has shape: {train_df.shape}\"), sep()\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-28T17:26:35.824142Z","iopub.execute_input":"2023-12-28T17:26:35.824867Z","iopub.status.idle":"2023-12-28T17:26:35.856024Z","shell.execute_reply.started":"2023-12-28T17:26:35.824836Z","shell.execute_reply":"2023-12-28T17:26:35.855017Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Train dataframe has shape: (6220, 3)\n----------------------------------------------------------------------------------------------------\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"         id                                               text  generated\n0  0059830c  Cars. Cars have been around since they became ...          0\n1  005db917  Transportation is a large necessity in most co...          0\n2  008f63e3  \"America's love affair with it's vehicles seem...          0\n3  00940276  How often do you ride in a car? Do you drive a...          0\n4  00c39458  Cars are a wonderful thing. They are perhaps o...          0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n      <th>generated</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0059830c</td>\n      <td>Cars. Cars have been around since they became ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>005db917</td>\n      <td>Transportation is a large necessity in most co...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>008f63e3</td>\n      <td>\"America's love affair with it's vehicles seem...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00940276</td>\n      <td>How often do you ride in a car? Do you drive a...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00c39458</td>\n      <td>Cars are a wonderful thing. They are perhaps o...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_df, test_df = train_test_split(train_df)","metadata":{"papermill":{"duration":0.148391,"end_time":"2022-08-31T07:03:04.558882","exception":false,"start_time":"2022-08-31T07:03:04.410491","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-28T17:26:37.774739Z","iopub.execute_input":"2023-12-28T17:26:37.775096Z","iopub.status.idle":"2023-12-28T17:26:37.782489Z","shell.execute_reply.started":"2023-12-28T17:26:37.775068Z","shell.execute_reply":"2023-12-28T17:26:37.781611Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"print(train_df.generated.value_counts())\nprint(test_df.generated.value_counts())","metadata":{"execution":{"iopub.status.busy":"2023-12-28T17:26:39.040844Z","iopub.execute_input":"2023-12-28T17:26:39.041213Z","iopub.status.idle":"2023-12-28T17:26:39.048631Z","shell.execute_reply.started":"2023-12-28T17:26:39.041183Z","shell.execute_reply":"2023-12-28T17:26:39.047558Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"generated\n0    2845\n1    1820\nName: count, dtype: int64\ngenerated\n0    951\n1    604\nName: count, dtype: int64\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# <b><span style='color:#F1A424'>|</span> Tokenizer</b><a class='anchor' id='tokenizer'></a> [↑](#top) \n\n***","metadata":{"papermill":{"duration":0.007561,"end_time":"2022-08-31T07:03:04.604916","exception":false,"start_time":"2022-08-31T07:03:04.597355","status":"completed"},"tags":[]}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(config.MODEL)\ntokenizer.save_pretrained(paths.OUTPUT_DIR + '/tokenizer/')\nprint(tokenizer)","metadata":{"papermill":{"duration":7.351568,"end_time":"2022-08-31T07:03:11.964298","exception":false,"start_time":"2022-08-31T07:03:04.61273","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-28T17:26:41.654985Z","iopub.execute_input":"2023-12-28T17:26:41.655348Z","iopub.status.idle":"2023-12-28T17:26:42.153567Z","shell.execute_reply.started":"2023-12-28T17:26:41.655319Z","shell.execute_reply":"2023-12-28T17:26:42.152417Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"DistilBertTokenizerFast(name_or_path='distilbert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True)\n","output_type":"stream"}]},{"cell_type":"code","source":"lengths = []\ntqdm_loader = tqdm(train_df['text'].fillna(\"\").values, total=len(train_df))\nfor text in tqdm_loader:\n    length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n    lengths.append(length)\n    \n# config.MAX_LEN = max(lengths) + 3 # cls & sep & sep\nLOGGER.info(f\"max_len: {config.MAX_LEN}\")\n_ = plt.hist(lengths, bins=25)","metadata":{"papermill":{"duration":5.893032,"end_time":"2022-08-31T07:03:17.886504","exception":false,"start_time":"2022-08-31T07:03:11.993472","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-28T17:26:45.440927Z","iopub.execute_input":"2023-12-28T17:26:45.441292Z","iopub.status.idle":"2023-12-28T17:26:52.828288Z","shell.execute_reply.started":"2023-12-28T17:26:45.441264Z","shell.execute_reply":"2023-12-28T17:26:52.827354Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4665 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23df6a66c98641c0bf36a382ccf724ef"}},"metadata":{}},{"name":"stderr","text":"Token indices sequence length is longer than the specified maximum sequence length for this model (1529 > 512). Running this sequence through the model will result in indexing errors\nmax_len: 512\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAigAAAGdCAYAAAA44ojeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAgKUlEQVR4nO3de3BU5cHH8V9CyBIum3Axu4lyiZaCEQQBjSvqtCVDwOhopS04qYOWQouJLRdRMiPBewBbdLAI6lhDRxRlptSKNTYNEKosAQMqAiJWNChuomJ2ASUJyfP+0ZczXUFlYZN9sn4/MztDznn27HP2wObLye5JgjHGCAAAwCKJsZ4AAADA1xEoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKyTFOsJnI7W1lYdOHBAPXr0UEJCQqynAwAAToExRocOHVJmZqYSE7/9HEmHDJQDBw6ob9++sZ4GAAA4Dfv379c555zzrWM6ZKD06NFD0n930O12x3g2AADgVIRCIfXt29f5Pv5tOmSgHP+xjtvtJlAAAOhgTuXtGbxJFgAAWIdAAQAA1iFQAACAdQgUAABgHQIFAABYh0ABAADWIVAAAIB1CBQAAGAdAgUAAFiHQAEAANYhUAAAgHUIFAAAYB0CBQAAWIdAAQAA1kmK9QTQ8QyY+1JUtvPBgvyobAcAEH84gwIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrRBQoLS0tmjdvnrKyspSSkqLzzjtP9957r4wxzhhjjEpKSpSRkaGUlBTl5uZq7969Yds5ePCgCgoK5Ha7lZaWpilTpujw4cPR2SMAANDhRRQoCxcu1LJly/SnP/1Ju3fv1sKFC7Vo0SI98sgjzphFixZpyZIlWr58uaqrq9WtWzfl5eXp6NGjzpiCggLt3LlTFRUVWrt2rTZu3Khp06ZFb68AAECHlmD+9/THd7j66qvl8Xj05JNPOssmTJiglJQUPf300zLGKDMzU7Nnz9Ztt90mSQoGg/J4PCorK9OkSZO0e/duZWdna+vWrRo1apQkqby8XFdddZU++ugjZWZmfuc8QqGQUlNTFQwG5Xa7I91nnKEBc1+KynY+WJAfle0AADqGSL5/R3QG5bLLLlNlZaXeffddSdKbb76pV199VePHj5ck7du3T4FAQLm5uc59UlNTlZOTI7/fL0ny+/1KS0tz4kSScnNzlZiYqOrq6pM+bmNjo0KhUNgNAADEr6RIBs+dO1ehUEiDBw9Wp06d1NLSovvvv18FBQWSpEAgIEnyeDxh9/N4PM66QCCg9PT08EkkJalXr17OmK8rLS3V3XffHclUAQBABxbRGZTnn39eK1eu1DPPPKNt27ZpxYoV+sMf/qAVK1a01fwkScXFxQoGg85t//79bfp4AAAgtiI6gzJnzhzNnTtXkyZNkiQNHTpUH374oUpLSzV58mR5vV5JUl1dnTIyMpz71dXVafjw4ZIkr9er+vr6sO0eO3ZMBw8edO7/dS6XSy6XK5KpAgCADiyiMyhffvmlEhPD79KpUye1trZKkrKysuT1elVZWemsD4VCqq6uls/nkyT5fD41NDSopqbGGbNu3Tq1trYqJyfntHcEAADEj4jOoFxzzTW6//771a9fP11wwQXavn27Fi9erF/96leSpISEBM2YMUP33XefBg4cqKysLM2bN0+ZmZm67rrrJEnnn3++xo0bp6lTp2r58uVqbm5WUVGRJk2adEqf4AEAAPEvokB55JFHNG/ePN1yyy2qr69XZmamfvOb36ikpMQZc/vtt+vIkSOaNm2aGhoadPnll6u8vFxdunRxxqxcuVJFRUUaM2aMEhMTNWHCBC1ZsiR6ewUAADq0iK6DYguugxJbXAcFAHA62uw6KAAAAO2BQAEAANYhUAAAgHUIFAAAYB0CBQAAWIdAAQAA1iFQAACAdQgUAABgnYiuJAtEExd8AwB8E86gAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADr8Cme75FofWoGAIC2xhkUAABgHQIFAABYh0ABAADWIVAAAIB1CBQAAGAdAgUAAFiHQAEAANYhUAAAgHUIFAAAYB0CBQAAWIdAAQAA1iFQAACAdQgUAABgHQIFAABYh0ABAADWIVAAAIB1CBQAAGAdAgUAAFiHQAEAANYhUAAAgHUIFAAAYB0CBQAAWIdAAQAA1iFQAACAdQgUAABgHQIFAABYh0ABAADWIVAAAIB1CBQAAGAdAgUAAFiHQAEAANYhUAAAgHUIFAAAYB0CBQAAWIdAAQAA1iFQAACAdQgUAABgHQIFAABYh0ABAADWIVAAAIB1CBQAAGAdAgUAAFiHQAEAANYhUAAAgHUIFAAAYB0CBQAAWIdAAQAA1iFQAACAdQgUAABgHQIFAABYh0ABAADWIVAAAIB1CBQAAGAdAgUAAFiHQAEAANYhUAAAgHUiDpSPP/5Yv/zlL9W7d2+lpKRo6NChev311531xhiVlJQoIyNDKSkpys3N1d69e8O2cfDgQRUUFMjtdistLU1TpkzR4cOHz3xvAABAXIgoUL744guNHj1anTt31ssvv6xdu3bpj3/8o3r27OmMWbRokZYsWaLly5erurpa3bp1U15eno4ePeqMKSgo0M6dO1VRUaG1a9dq48aNmjZtWvT2CgAAdGgJxhhzqoPnzp2r1157Tf/+979Put4Yo8zMTM2ePVu33XabJCkYDMrj8aisrEyTJk3S7t27lZ2dra1bt2rUqFGSpPLycl111VX66KOPlJmZ+Z3zCIVCSk1NVTAYlNvtPtXpf+8NmPtSrKfQJj5YkB/rKQAATkEk378jOoPy97//XaNGjdLPf/5zpaen66KLLtITTzzhrN+3b58CgYByc3OdZampqcrJyZHf75ck+f1+paWlOXEiSbm5uUpMTFR1dfVJH7exsVGhUCjsBgAA4ldEgfL+++9r2bJlGjhwoF555RVNnz5dv/vd77RixQpJUiAQkCR5PJ6w+3k8HmddIBBQenp62PqkpCT16tXLGfN1paWlSk1NdW59+/aNZNoAAKCDiShQWltbNWLECD3wwAO66KKLNG3aNE2dOlXLly9vq/lJkoqLixUMBp3b/v372/TxAABAbEUUKBkZGcrOzg5bdv7556u2tlaS5PV6JUl1dXVhY+rq6px1Xq9X9fX1YeuPHTumgwcPOmO+zuVyye12h90AAED8iihQRo8erT179oQte/fdd9W/f39JUlZWlrxeryorK531oVBI1dXV8vl8kiSfz6eGhgbV1NQ4Y9atW6fW1lbl5OSc9o4AAID4kRTJ4JkzZ+qyyy7TAw88oF/84hfasmWLHn/8cT3++OOSpISEBM2YMUP33XefBg4cqKysLM2bN0+ZmZm67rrrJP33jMu4ceOcHw01NzerqKhIkyZNOqVP8AAAgPgXUaBcfPHFWrNmjYqLi3XPPfcoKytLDz/8sAoKCpwxt99+u44cOaJp06apoaFBl19+ucrLy9WlSxdnzMqVK1VUVKQxY8YoMTFREyZM0JIlS6K3VwAAoEOL6DootuA6KKeH66AAAGKpza6DAgAA0B4IFAAAYB0CBQAAWIdAAQAA1iFQAACAdQgUAABgHQIFAABYh0ABAADWiehKsoCNonUBOi74BgD24AwKAACwDoECAACsQ6AAAADrECgAAMA6vEm2A4jX30IMAMA34QwKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDpnFCgLFixQQkKCZsyY4Sw7evSoCgsL1bt3b3Xv3l0TJkxQXV1d2P1qa2uVn5+vrl27Kj09XXPmzNGxY8fOZCoAACCOnHagbN26VY899pguvPDCsOUzZ87Uiy++qNWrV6uqqkoHDhzQ9ddf76xvaWlRfn6+mpqatGnTJq1YsUJlZWUqKSk5/b0AAABx5bQC5fDhwyooKNATTzyhnj17OsuDwaCefPJJLV68WD/5yU80cuRIPfXUU9q0aZM2b94sSfrnP/+pXbt26emnn9bw4cM1fvx43XvvvVq6dKmampqis1cAAKBDO61AKSwsVH5+vnJzc8OW19TUqLm5OWz54MGD1a9fP/n9fkmS3+/X0KFD5fF4nDF5eXkKhULauXPnSR+vsbFRoVAo7AYAAOJXUqR3WLVqlbZt26atW7eesC4QCCg5OVlpaWlhyz0ejwKBgDPmf+Pk+Prj606mtLRUd999d6RTBQAAHVREZ1D279+v3//+91q5cqW6dOnSVnM6QXFxsYLBoHPbv39/uz02AABofxEFSk1Njerr6zVixAglJSUpKSlJVVVVWrJkiZKSkuTxeNTU1KSGhoaw+9XV1cnr9UqSvF7vCZ/qOf718TFf53K55Ha7w24AACB+RRQoY8aM0Y4dO/TGG284t1GjRqmgoMD5c+fOnVVZWencZ8+ePaqtrZXP55Mk+Xw+7dixQ/X19c6YiooKud1uZWdnR2m3AABARxbRe1B69OihIUOGhC3r1q2bevfu7SyfMmWKZs2apV69esntduvWW2+Vz+fTpZdeKkkaO3assrOzdeONN2rRokUKBAK68847VVhYKJfLFaXdAgAAHVnEb5L9Lg899JASExM1YcIENTY2Ki8vT48++qizvlOnTlq7dq2mT58un8+nbt26afLkybrnnnuiPRUAANBBJRhjTKwnEalQKKTU1FQFg8HvxftRBsx9KdZT+F74YEF+rKcAAHEtku/f/C4eAABgHQIFAABYh0ABAADWIVAAAIB1CBQAAGAdAgUAAFiHQAEAANYhUAAAgHUIFAAAYB0CBQAAWIdAAQAA1iFQAACAdQgUAABgHQIFAABYh0ABAADWIVAAAIB1CBQAAGAdAgUAAFiHQAEAANZJivUEAFsMmPtSVLbzwYL8qGwHAL7POIMCAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOskxXoC8WzA3JdiPQUAADokzqAAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsE5SJINLS0v117/+Ve+8845SUlJ02WWXaeHChRo0aJAz5ujRo5o9e7ZWrVqlxsZG5eXl6dFHH5XH43HG1NbWavr06Vq/fr26d++uyZMnq7S0VElJEU0HsNKAuS9FZTsfLMiPynYAoCOK6AxKVVWVCgsLtXnzZlVUVKi5uVljx47VkSNHnDEzZ87Uiy++qNWrV6uqqkoHDhzQ9ddf76xvaWlRfn6+mpqatGnTJq1YsUJlZWUqKSmJ3l4BAIAOLcEYY073zp9++qnS09NVVVWlK6+8UsFgUGeddZaeeeYZ/exnP5MkvfPOOzr//PPl9/t16aWX6uWXX9bVV1+tAwcOOGdVli9frjvuuEOffvqpkpOTv/NxQ6GQUlNTFQwG5Xa7T3f6bS5a/5PG9xNnUADEm0i+f5/Re1CCwaAkqVevXpKkmpoaNTc3Kzc31xkzePBg9evXT36/X5Lk9/s1dOjQsB/55OXlKRQKaefOnSd9nMbGRoVCobAbAACIX6cdKK2trZoxY4ZGjx6tIUOGSJICgYCSk5OVlpYWNtbj8SgQCDhj/jdOjq8/vu5kSktLlZqa6tz69u17utMGAAAdwGkHSmFhod5++22tWrUqmvM5qeLiYgWDQee2f//+Nn9MAAAQO6f1sZmioiKtXbtWGzdu1DnnnOMs93q9ampqUkNDQ9hZlLq6Onm9XmfMli1bwrZXV1fnrDsZl8sll8t1OlMFAAAdUERnUIwxKioq0po1a7Ru3TplZWWFrR85cqQ6d+6syspKZ9mePXtUW1srn88nSfL5fNqxY4fq6+udMRUVFXK73crOzj6TfQEAAHEiojMohYWFeuaZZ/TCCy+oR48ezntGUlNTlZKSotTUVE2ZMkWzZs1Sr1695Ha7deutt8rn8+nSSy+VJI0dO1bZ2dm68cYbtWjRIgUCAd15550qLCzkLAkAAJAUYaAsW7ZMkvSjH/0obPlTTz2lm266SZL00EMPKTExURMmTAi7UNtxnTp10tq1azV9+nT5fD5169ZNkydP1j333HNmewIAAOLGGV0HJVa4Dgq+D7gOCoB4027XQQEAAGgLBAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALBOUqwnAODkBsx9KSrb+WBBflS2AwDtiTMoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrJMV6AgDa1oC5L0VlOx8syI/KdgDgVHAGBQAAWIdAAQAA1iFQAACAdQgUAABgHQIFAABYh0ABAADWIVAAAIB1CBQAAGAdAgUAAFiHQAEAANYhUAAAgHUIFAAAYB1+WSCAU8IvHQTQnjiDAgAArMMZFADtijMxAE4FgXIS0XoBBQAAp4cf8QAAAOsQKAAAwDoECgAAsA6BAgAArMObZAF0SHwaCIhvnEEBAADWIVAAAIB1CBQAAGAdAgUAAFiHN8kC+F7jzbaAnWJ6BmXp0qUaMGCAunTpopycHG3ZsiWW0wEAAJaIWaA899xzmjVrlubPn69t27Zp2LBhysvLU319faymBAAALBGzQFm8eLGmTp2qm2++WdnZ2Vq+fLm6du2qP//5z7GaEgAAsERM3oPS1NSkmpoaFRcXO8sSExOVm5srv99/wvjGxkY1NjY6XweDQUlSKBRqk/m1Nn7ZJtsFEL/6zVwd6ymEefvuvFhPATjB8e/bxpjvHBuTQPnss8/U0tIij8cTttzj8eidd945YXxpaanuvvvuE5b37du3zeYIAB1Z6sOxngHwzQ4dOqTU1NRvHdMhPsVTXFysWbNmOV+3trbq4MGD6t27txISEr7z/qFQSH379tX+/fvldrvbcqr4BhwDO3AcYo9jYAeOQ2wYY3To0CFlZmZ+59iYBEqfPn3UqVMn1dXVhS2vq6uT1+s9YbzL5ZLL5QpblpaWFvHjut1u/iLGGMfADhyH2OMY2IHj0P6+68zJcTF5k2xycrJGjhypyspKZ1lra6sqKyvl8/liMSUAAGCRmP2IZ9asWZo8ebJGjRqlSy65RA8//LCOHDmim2++OVZTAgAAlohZoEycOFGffvqpSkpKFAgENHz4cJWXl5/wxtlocLlcmj9//gk/JkL74RjYgeMQexwDO3Ac7JdgTuWzPgAAAO2IXxYIAACsQ6AAAADrECgAAMA6BAoAALBO3AfK0qVLNWDAAHXp0kU5OTnasmVLrKcUN+666y4lJCSE3QYPHuysP3r0qAoLC9W7d291795dEyZMOOHifLW1tcrPz1fXrl2Vnp6uOXPm6NixY+29Kx3Kxo0bdc011ygzM1MJCQn629/+FrbeGKOSkhJlZGQoJSVFubm52rt3b9iYgwcPqqCgQG63W2lpaZoyZYoOHz4cNuatt97SFVdcoS5duqhv375atGhRW+9ah/Fdx+Cmm2464d/GuHHjwsZwDM5MaWmpLr74YvXo0UPp6em67rrrtGfPnrAx0XoN2rBhg0aMGCGXy6Uf/OAHKisra+vdg+I8UJ577jnNmjVL8+fP17Zt2zRs2DDl5eWpvr4+1lOLGxdccIE++eQT5/bqq68662bOnKkXX3xRq1evVlVVlQ4cOKDrr7/eWd/S0qL8/Hw1NTVp06ZNWrFihcrKylRSUhKLXekwjhw5omHDhmnp0qUnXb9o0SItWbJEy5cvV3V1tbp166a8vDwdPXrUGVNQUKCdO3eqoqJCa9eu1caNGzVt2jRnfSgU0tixY9W/f3/V1NTowQcf1F133aXHH3+8zfevI/iuYyBJ48aNC/u38eyzz4at5xicmaqqKhUWFmrz5s2qqKhQc3Ozxo4dqyNHjjhjovEatG/fPuXn5+vHP/6x3njjDc2YMUO//vWv9corr7Tr/n4vmTh2ySWXmMLCQufrlpYWk5mZaUpLS2M4q/gxf/58M2zYsJOua2hoMJ07dzarV692lu3evdtIMn6/3xhjzD/+8Q+TmJhoAoGAM2bZsmXG7XabxsbGNp17vJBk1qxZ43zd2tpqvF6vefDBB51lDQ0NxuVymWeffdYYY8yuXbuMJLN161ZnzMsvv2wSEhLMxx9/bIwx5tFHHzU9e/YMOw533HGHGTRoUBvvUcfz9WNgjDGTJ08211577Tfeh2MQffX19UaSqaqqMsZE7zXo9ttvNxdccEHYY02cONHk5eW19S5978XtGZSmpibV1NQoNzfXWZaYmKjc3Fz5/f4Yziy+7N27V5mZmTr33HNVUFCg2tpaSVJNTY2am5vDnv/BgwerX79+zvPv9/s1dOjQsIvz5eXlKRQKaefOne27I3Fi3759CgQCYc97amqqcnJywp73tLQ0jRo1yhmTm5urxMREVVdXO2OuvPJKJScnO2Py8vK0Z88effHFF+20Nx3bhg0blJ6erkGDBmn69On6/PPPnXUcg+gLBoOSpF69ekmK3muQ3+8P28bxMXwfaXtxGyifffaZWlpaTrgyrcfjUSAQiNGs4ktOTo7KyspUXl6uZcuWad++fbriiit06NAhBQIBJScnn/BLHf/3+Q8EAic9PsfXIXLHn7dv+3sfCASUnp4etj4pKUm9evXi2ETJuHHj9Je//EWVlZVauHChqqqqNH78eLW0tEjiGERba2urZsyYodGjR2vIkCGSFLXXoG8aEwqF9NVXX7XF7uD/xexS9+j4xo8f7/z5wgsvVE5Ojvr376/nn39eKSkpMZwZEFuTJk1y/jx06FBdeOGFOu+887RhwwaNGTMmhjOLT4WFhXr77bfD3gOHji9uz6D06dNHnTp1OuEd23V1dfJ6vTGaVXxLS0vTD3/4Q7333nvyer1qampSQ0ND2Jj/ff69Xu9Jj8/xdYjc8eft2/7ee73eE94ofuzYMR08eJBj00bOPfdc9enTR++9954kjkE0FRUVae3atVq/fr3OOeccZ3m0XoO+aYzb7eY/Ym0sbgMlOTlZI0eOVGVlpbOstbVVlZWV8vl8MZxZ/Dp8+LD+85//KCMjQyNHjlTnzp3Dnv89e/aotrbWef59Pp927NgR9kJdUVEht9ut7Ozsdp9/PMjKypLX6w173kOhkKqrq8Oe94aGBtXU1Dhj1q1bp9bWVuXk5DhjNm7cqObmZmdMRUWFBg0apJ49e7bT3sSPjz76SJ9//rkyMjIkcQyiwRijoqIirVmzRuvWrVNWVlbY+mi9Bvl8vrBtHB/D95F2EOt36balVatWGZfLZcrKysyuXbvMtGnTTFpaWtg7tnH6Zs+ebTZs2GD27dtnXnvtNZObm2v69Olj6uvrjTHG/Pa3vzX9+vUz69atM6+//rrx+XzG5/M59z927JgZMmSIGTt2rHnjjTdMeXm5Oeuss0xxcXGsdqlDOHTokNm+fbvZvn27kWQWL15stm/fbj788ENjjDELFiwwaWlp5oUXXjBvvfWWufbaa01WVpb56quvnG2MGzfOXHTRRaa6utq8+uqrZuDAgeaGG25w1jc0NBiPx2NuvPFG8/bbb5tVq1aZrl27mscee6zd99dG33YMDh06ZG677Tbj9/vNvn37zL/+9S8zYsQIM3DgQHP06FFnGxyDMzN9+nSTmppqNmzYYD755BPn9uWXXzpjovEa9P7775uuXbuaOXPmmN27d5ulS5eaTp06mfLy8nbd3++juA4UY4x55JFHTL9+/UxycrK55JJLzObNm2M9pbgxceJEk5GRYZKTk83ZZ59tJk6caN577z1n/VdffWVuueUW07NnT9O1a1fz05/+1HzyySdh2/jggw/M+PHjTUpKiunTp4+ZPXu2aW5ubu9d6VDWr19vJJ1wmzx5sjHmvx81njdvnvF4PMblcpkxY8aYPXv2hG3j888/NzfccIPp3r27cbvd5uabbzaHDh0KG/Pmm2+ayy+/3LhcLnP22WebBQsWtNcuWu/bjsGXX35pxo4da8466yzTuXNn079/fzN16tQT/mPEMTgzJ3v+JZmnnnrKGROt16D169eb4cOHm+TkZHPuueeGPQbaToIxxrT3WRsAAIBvE7fvQQEAAB0XgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6/wcDCn4CUPC21QAAAABJRU5ErkJggg=="},"metadata":{}}]},{"cell_type":"code","source":"def prepare_input(cfg, text, tokenizer):\n    \"\"\"\n    This function tokenizes the input text with the configured padding and truncation. Then,\n    returns the input dictionary, which contains the following keys: \"input_ids\",\n    \"token_type_ids\" and \"attention_mask\". Each value is a torch.tensor.\n    :param cfg: configuration class with a TOKENIZER attribute.\n    :param text: a numpy array where each value is a text as string.\n    :return inputs: python dictionary where values are torch tensors.\n    \"\"\"\n    inputs = tokenizer.encode_plus(\n        text, \n        return_tensors=None, \n        add_special_tokens=True, \n        max_length=cfg.MAX_LEN,\n        padding='max_length', # TODO: check padding to max sequence in batch\n        truncation=True\n    )\n    for k, v in inputs.items():\n        inputs[k] = torch.tensor(v, dtype=torch.long) # TODO: check dtypes\n    return inputs\n\n\ndef collate(inputs):\n    \"\"\"\n    It truncates the inputs to the maximum sequence length in the batch. \n    \"\"\"\n    mask_len = int(inputs[\"attention_mask\"].sum(axis=1).max()) # Get batch's max sequence length\n    for k, v in inputs.items():\n        inputs[k] = inputs[k][:,:mask_len]\n    return inputs\n\n\nclass CustomDataset(Dataset):\n    def __init__(self, cfg, df, tokenizer):\n        self.cfg = cfg\n        self.texts = df['text'].values\n        self.labels = df['generated'].values\n        self.tokenizer = tokenizer\n        self.text_ids = df['id'].values\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, item):\n        output = {}\n        output[\"inputs\"] = prepare_input(self.cfg, self.texts[item], self.tokenizer)\n        output[\"labels\"] = torch.tensor(self.labels[item], dtype=torch.float) # TODO: check dtypes\n        output[\"ids\"] = self.text_ids[item]\n        return output","metadata":{"papermill":{"duration":0.020447,"end_time":"2022-08-31T07:03:17.916566","exception":false,"start_time":"2022-08-31T07:03:17.896119","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-28T17:26:52.830447Z","iopub.execute_input":"2023-12-28T17:26:52.831084Z","iopub.status.idle":"2023-12-28T17:26:52.840951Z","shell.execute_reply.started":"2023-12-28T17:26:52.831056Z","shell.execute_reply":"2023-12-28T17:26:52.840013Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# <b><span style='color:#F1A424'>|</span> Model</b><a class='anchor' id='model'></a> [↑](#top) \n\n***","metadata":{"papermill":{"duration":0.008073,"end_time":"2022-08-31T07:03:17.933189","exception":false,"start_time":"2022-08-31T07:03:17.925116","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class MeanPooling(nn.Module):\n    def __init__(self):\n        super(MeanPooling, self).__init__()\n        \n    def forward(self, last_hidden_state, attention_mask):\n        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n        sum_mask = input_mask_expanded.sum(1)\n        sum_mask = torch.clamp(sum_mask, min=1e-9)\n        mean_embeddings = sum_embeddings / sum_mask\n        return mean_embeddings\n    \n\nclass CustomModel(nn.Module):\n    def __init__(self, cfg, config_path=None, pretrained=False):\n        super().__init__()\n        self.cfg = cfg\n        self.dropout = 0.2\n        if config_path is None: \n            self.config = DistilBertConfig.from_pretrained(self.cfg.MODEL, output_hidden_states=True)\n            self.config.hidden_dropout = 0.\n            self.config.hidden_dropout_prob = 0.\n            self.config.attention_dropout = 0.\n            self.config.attention_probs_dropout_prob = 0.\n        # Load config from a file.\n        else:\n            self.config = torch.load(config_path)\n        \n        if pretrained:\n            self.model = DistilBertModel.from_pretrained(self.cfg.MODEL, config=self.config)\n        else:\n            self.model = DistilBertModel(self.config)\n            \n        for param in self.model.parameters():\n            param.requires_grad = True\n            \n        if self.cfg.GRADIENT_CHECKPOINTING:\n            self.model.gradient_checkpointing_enable()\n          \n        # Add MeanPooling and Linear head at the end to transform the Model into a RegressionModel\n        self.pool = MeanPooling()\n        self.head = nn.Sequential(\n            nn.Linear(self.config.hidden_size, 64),\n            nn.BatchNorm1d(64),\n            nn.ReLU(),\n            nn.Dropout(self.dropout),\n            nn.Linear(64, 16),\n            nn.BatchNorm1d(16),\n            nn.ReLU(),\n            nn.Dropout(self.dropout),\n            nn.Linear(16, 1)\n        )\n        self._init_weights(self.head)\n        \n    def _init_weights(self, module):\n        \"\"\"\n        This method initializes weights for different types of layers. The type of layers \n        supported are nn.Linear, nn.Embedding and nn.LayerNorm.\n        \"\"\"\n        if isinstance(module, nn.Linear):\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n            if module.bias is not None:\n                module.bias.data.zero_()\n        elif isinstance(module, nn.Embedding):\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n            if module.padding_idx is not None:\n                module.weight.data[module.padding_idx].zero_()\n        elif isinstance(module, nn.LayerNorm):\n            module.bias.data.zero_()\n            module.weight.data.fill_(1.0)\n        \n    def feature(self, inputs):\n        outputs = self.model(**inputs)\n        last_hidden_states = outputs[0]  # For DistilBert, outputs is a tuple with hidden states as the first item\n        feature = self.pool(last_hidden_states, inputs['attention_mask'])\n        return feature\n\n    def forward(self, inputs):\n        \"\"\"\n        This method makes a forward pass through the model, the MeanPooling layer and finally\n        then through the Linear layer to get a regression value.\n        \"\"\"\n        feature = self.feature(inputs)\n        output = self.head(feature)\n        return output","metadata":{"papermill":{"duration":0.033105,"end_time":"2022-08-31T07:03:17.97447","exception":false,"start_time":"2022-08-31T07:03:17.941365","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-28T17:26:52.842385Z","iopub.execute_input":"2023-12-28T17:26:52.843025Z","iopub.status.idle":"2023-12-28T17:26:52.862193Z","shell.execute_reply.started":"2023-12-28T17:26:52.842999Z","shell.execute_reply":"2023-12-28T17:26:52.861176Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# <b><span style='color:#F1A424'>|</span> Train and Validation Functions</b><a class='anchor' id='functions'></a> [↑](#top) \n\n***\n    \n- [torch.cuda.amp.GradScaler](https://pytorch.org/docs/stable/amp.html#torch.cuda.amp.GradScaler): This class helps writing compute efficient training loops, so we dont get OOM errors. Also, one common error in any large deep learning model is the problem of underflowing gradients (i.e. your gradients are too small to take into account). `float16` tensors often don't take into account extremely small variations. To prevent this we can scale our gradients by some factor so that they aren't flushed to zero. Not to be confused with vanishing gradients, this gradients still might contribute to the learning process however are skipped because of computational limits.\n- [torch.autocast](https://pytorch.org/docs/stable/amp.html#torch.autocast)","metadata":{"papermill":{"duration":0.008452,"end_time":"2022-08-31T07:03:18.041557","exception":false,"start_time":"2022-08-31T07:03:18.033105","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\n\ndef asMinutes(s):\n    m = math.floor(s / 60)\n    s -= m * 60\n    return '%dm %ds' % (m, s)\n\n\ndef timeSince(since, percent):\n    now = time.time()\n    s = now - since\n    es = s / (percent)\n    rs = es - s\n    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n\n\ndef train_epoch(train_loader, model, criterion, optimizer, epoch, scheduler, device):\n    \"\"\"One epoch training pass.\"\"\"\n    model.train() # set model in train mode\n    scaler = torch.cuda.amp.GradScaler(enabled=config.APEX) # Automatic Mixed Precision tries to match each op to its appropriate datatype.\n    losses = AverageMeter() # initiate AverageMeter to track the loss.\n    start = end = time.time() # track the execution time.\n    global_step = 0\n    \n    # ========== ITERATE OVER TRAIN BATCHES ============\n    with tqdm(train_loader, unit=\"train_batch\", desc='Train') as tqdm_train_loader:\n        for step, batch in enumerate(tqdm_train_loader):\n            inputs = batch.pop(\"inputs\")\n            labels = batch.pop(\"labels\")\n            inputs = collate(inputs) # collate inputs\n            for k, v in inputs.items(): # send each tensor value to `device`\n                inputs[k] = v.to(device)\n            labels = labels.to(device) # send labels to `device`\n            batch_size = labels.size(0)\n            with torch.cuda.amp.autocast(enabled=config.APEX):\n                y_preds = model(inputs) # forward propagation pass\n                loss = criterion(y_preds, labels.unsqueeze(1)) # get loss\n            if config.GRADIENT_ACCUMULATION_STEPS > 1:\n                loss = loss / config.GRADIENT_ACCUMULATION_STEPS\n            losses.update(loss.item(), batch_size) # update loss function tracking\n            scaler.scale(loss).backward() # backward propagation pass\n            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), config.MAX_GRAD_NORM)\n\n            if (step + 1) % config.GRADIENT_ACCUMULATION_STEPS == 0:\n                scaler.step(optimizer) # update optimizer parameters\n                scaler.update()\n                optimizer.zero_grad() # zero out the gradients\n                global_step += 1\n                if config.BATCH_SCHEDULER:\n                    scheduler.step() # update learning rate\n            end = time.time() # get finish time\n\n            # ========== LOG INFO ==========\n            if step % config.PRINT_FREQ == 0 or step == (len(train_loader)-1):\n                print('Epoch: [{0}][{1}/{2}] '\n                      'Elapsed {remain:s} '\n                      'Loss: {loss.avg:.4f} '\n                      'Grad: {grad_norm:.4f}  '\n                      'LR: {lr:.8f}  '\n                      .format(epoch+1, step, len(train_loader), \n                              remain=timeSince(start, float(step+1)/len(train_loader)),\n                              loss=losses,\n                              grad_norm=grad_norm,\n                              lr=scheduler.get_lr()[0]))\n\n\n    return losses.avg\n\n\ndef valid_epoch(valid_loader, model, criterion, device):\n    model.eval() # set model in evaluation mode\n    losses = AverageMeter() # initiate AverageMeter for tracking the loss.\n    prediction_dict = {}\n    preds = []\n    start = end = time.time() # track the execution time.\n    with tqdm(valid_loader, unit=\"valid_batch\", desc='Validation') as tqdm_valid_loader:\n        for step, batch in enumerate(tqdm_valid_loader):\n            inputs = batch.pop(\"inputs\")\n            labels = batch.pop(\"labels\")\n            ids = batch.pop(\"ids\")\n            inputs = collate(inputs) # collate inputs\n            for k, v in inputs.items():\n                inputs[k] = v.to(device) # send inputs to device\n            labels = labels.to(device)\n            batch_size = labels.size(0)\n            with torch.no_grad():\n                y_preds = model(inputs) # forward propagation pass\n                loss = criterion(y_preds, labels.unsqueeze(1)) # get loss\n            if config.GRADIENT_ACCUMULATION_STEPS > 1:\n                loss = loss / config.GRADIENT_ACCUMULATION_STEPS\n            losses.update(loss.item(), batch_size) # update loss function tracking\n            preds.append(y_preds.to('cpu').numpy()) # save predictions\n            end = time.time() # get finish time\n\n            # ========== LOG INFO ==========\n            if step % config.PRINT_FREQ == 0 or step == (len(valid_loader)-1):\n                print('EVAL: [{0}/{1}] '\n                      'Elapsed {remain:s} '\n                      'Loss: {loss.avg:.4f} '\n                      .format(step, len(valid_loader),\n                              loss=losses,\n                              remain=timeSince(start, float(step+1)/len(valid_loader))))\n\n                \n    prediction_dict[\"predictions\"] = np.concatenate(preds) # np.array() of shape (fold_size, target_cols)\n    prediction_dict[\"ids\"] = ids\n    return losses.avg, prediction_dict","metadata":{"papermill":{"duration":0.030759,"end_time":"2022-08-31T07:03:18.08056","exception":false,"start_time":"2022-08-31T07:03:18.049801","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-28T17:26:52.864575Z","iopub.execute_input":"2023-12-28T17:26:52.864921Z","iopub.status.idle":"2023-12-28T17:26:52.897421Z","shell.execute_reply.started":"2023-12-28T17:26:52.864891Z","shell.execute_reply":"2023-12-28T17:26:52.896494Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# <b><span style='color:#F1A424'>|</span> Train Loop</b><a class='anchor' id='train_loop'></a> [↑](#top) \n\n***","metadata":{"papermill":{"duration":0.0081,"end_time":"2022-08-31T07:03:18.100232","exception":false,"start_time":"2022-08-31T07:03:18.092132","status":"completed"},"tags":[]}},{"cell_type":"code","source":"test_df","metadata":{"execution":{"iopub.status.busy":"2023-12-28T17:26:52.898638Z","iopub.execute_input":"2023-12-28T17:26:52.898902Z","iopub.status.idle":"2023-12-28T17:26:52.920499Z","shell.execute_reply.started":"2023-12-28T17:26:52.898880Z","shell.execute_reply":"2023-12-28T17:26:52.919310Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"                id                                               text  generated\n5995  EC35456D4E07  Conserve energy and resources,some businesses ...          0\n1425  638D7F913AAB  Do you think the greatest accomplishment in th...          1\n3567  EBE636368EBC  People make there own decisions because they d...          1\n2560  B4B82E063D04  is setting an good example by your own behavio...          1\n5151  C1314085435C  I agree with Ralph waldo Emerson because he sa...          0\n...            ...                                                ...        ...\n4164  7ACF284A8B7C  I think that work in groups is more benefit. B...          0\n1599  71F12F9F01DE  I agree with this prompt many cases it is impo...          1\n3300  DF149975C610  I agree with emerson's statement. I will grow ...          1\n3669  F0B44890C961  Dear Sir or Madam:Yes school should control st...          1\n1822  80CCEFCCD166  Some may say that working in a group is better...          1\n\n[1555 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n      <th>generated</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5995</th>\n      <td>EC35456D4E07</td>\n      <td>Conserve energy and resources,some businesses ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1425</th>\n      <td>638D7F913AAB</td>\n      <td>Do you think the greatest accomplishment in th...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3567</th>\n      <td>EBE636368EBC</td>\n      <td>People make there own decisions because they d...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2560</th>\n      <td>B4B82E063D04</td>\n      <td>is setting an good example by your own behavio...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5151</th>\n      <td>C1314085435C</td>\n      <td>I agree with Ralph waldo Emerson because he sa...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4164</th>\n      <td>7ACF284A8B7C</td>\n      <td>I think that work in groups is more benefit. B...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1599</th>\n      <td>71F12F9F01DE</td>\n      <td>I agree with this prompt many cases it is impo...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3300</th>\n      <td>DF149975C610</td>\n      <td>I agree with emerson's statement. I will grow ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3669</th>\n      <td>F0B44890C961</td>\n      <td>Dear Sir or Madam:Yes school should control st...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1822</th>\n      <td>80CCEFCCD166</td>\n      <td>Some may say that working in a group is better...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>1555 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def train_loop(train_df, test_df):\n    \n\n    # ======== DATASETS ==========\n    train_dataset = CustomDataset(config, train_df, tokenizer)\n    valid_dataset = CustomDataset(config, test_df, tokenizer)\n    \n    # ======== DATALOADERS ==========\n    train_loader = DataLoader(train_dataset,\n                              batch_size=config.BATCH_SIZE_TRAIN, \n                              shuffle=True,\n                              pin_memory=True, drop_last=True)\n    valid_loader = DataLoader(valid_dataset,\n                              batch_size=config.BATCH_SIZE_VALID,\n                              shuffle=False,\n                              pin_memory=True, drop_last=False)\n    \n    # ======== MODEL ==========\n    model = CustomModel(config, config_path=None, pretrained=True)\n    torch.save(model.config, paths.OUTPUT_DIR + '/config.pth')\n    model.to(device)\n\n    optimizer_parameters = get_optimizer_params(model,\n                                                encoder_lr=config.ENCODER_LR, \n                                                decoder_lr=config.DECODER_LR,\n                                                weight_decay=config.WEIGHT_DECAY)\n    optimizer = AdamW(optimizer_parameters,\n                      lr=config.ENCODER_LR,\n                      eps=config.EPS,\n                      betas=config.BETAS)\n    \n    scheduler = OneCycleLR(\n        optimizer,\n        max_lr=1e-5,\n        epochs=config.EPOCHS,\n        steps_per_epoch=len(train_loader),\n        pct_start=0.1,\n        anneal_strategy=\"cos\",\n        final_div_factor=100,\n    )\n\n    # ======= LOSS ==========\n    criterion = nn.BCEWithLogitsLoss()\n    \n    best_score = -np.inf\n    # ====== ITERATE EPOCHS ========\n    for epoch in range(config.EPOCHS):\n\n        start_time = time.time()\n\n        # ======= TRAIN ==========\n        avg_loss = train_epoch(train_loader, model, criterion, optimizer, epoch, scheduler, device)\n\n        # ======= EVALUATION ==========\n        avg_val_loss, prediction_dict = valid_epoch(valid_loader, model, criterion, device)\n        predictions = prediction_dict[\"predictions\"]\n        valid_labels = test_df.generated.values.tolist()\n        # ======= SCORING ==========\n        score = get_score(valid_labels, sigmoid(predictions))\n\n        elapsed = time.time() - start_time\n\n        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}')\n        \n\n            \n        if score > best_score:\n            best_score = score\n            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n            torch.save(model.state_dict(),\n                        paths.OUTPUT_DIR + f\"/{config.MODEL.replace('/', '_')}_best.pth\")\n            best_model_predictions = predictions\n\n    test_df[\"preds\"] = best_model_predictions\n\n    torch.cuda.empty_cache()\n    gc.collect()\n    \n    return test_df","metadata":{"papermill":{"duration":0.033332,"end_time":"2022-08-31T07:03:18.141812","exception":false,"start_time":"2022-08-31T07:03:18.10848","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-28T17:27:02.136380Z","iopub.execute_input":"2023-12-28T17:27:02.137423Z","iopub.status.idle":"2023-12-28T17:27:02.150019Z","shell.execute_reply.started":"2023-12-28T17:27:02.137386Z","shell.execute_reply":"2023-12-28T17:27:02.148974Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"from torch.utils.checkpoint import checkpoint","metadata":{"execution":{"iopub.status.busy":"2023-12-28T17:27:02.847751Z","iopub.execute_input":"2023-12-28T17:27:02.848520Z","iopub.status.idle":"2023-12-28T17:27:02.853554Z","shell.execute_reply.started":"2023-12-28T17:27:02.848488Z","shell.execute_reply":"2023-12-28T17:27:02.852529Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"# <b><span style='color:#F1A424'>|</span> Train</b><a class='anchor' id='train'></a> [↑](#top) \n\n***","metadata":{}},{"cell_type":"code","source":"if __name__ == '__main__':\n    def get_result(oof_df):\n        labels = oof_df[\"generated\"].values\n        preds = oof_df[\"preds\"].values\n        score = get_score(labels, preds)\n        LOGGER.info(f'Score: {score:<.4f}')\n    \n    if config.TRAIN:\n        oof_df = pd.DataFrame()\n        _oof_df = train_loop(train_df, test_df)\n        oof_df = pd.concat([oof_df, _oof_df])\n        get_result(_oof_df)\n            \n        oof_df = oof_df.reset_index(drop=True)\n        LOGGER.info(f\"========== CV ==========\")\n        get_result(oof_df)\n        oof_df.to_csv(paths.OUTPUT_DIR + '/oof_df.csv', index=False)","metadata":{"papermill":{"duration":11935.46951,"end_time":"2022-08-31T10:22:13.621316","exception":false,"start_time":"2022-08-31T07:03:18.151806","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-28T17:27:04.301581Z","iopub.execute_input":"2023-12-28T17:27:04.302636Z","iopub.status.idle":"2023-12-28T17:41:51.799868Z","shell.execute_reply.started":"2023-12-28T17:27:04.302601Z","shell.execute_reply":"2023-12-28T17:41:51.798608Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"Train:   0%|          | 0/72 [00:00<?, ?train_batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac7b69b4bfa1489d8dec8b2e6af3407d"}},"metadata":{}},{"name":"stdout","text":"Epoch: [1][0/72] Elapsed 0m 2s (remain 2m 55s) Loss: 0.7477 Grad: 243199.7656  LR: 0.00000042  \nEpoch: [1][20/72] Elapsed 0m 46s (remain 1m 53s) Loss: 0.7060 Grad: 177178.6250  LR: 0.00000668  \nEpoch: [1][40/72] Elapsed 1m 30s (remain 1m 8s) Loss: 0.6954 Grad: 156571.1719  LR: 0.00000999  \nEpoch: [1][60/72] Elapsed 2m 15s (remain 0m 24s) Loss: 0.6829 Grad: 144546.7969  LR: 0.00000984  \nEpoch: [1][71/72] Elapsed 2m 39s (remain 0m 0s) Loss: 0.6799 Grad: 133482.0469  LR: 0.00000968  \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/49 [00:00<?, ?valid_batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90fbb3bb18124949ad4e42868d7ac06a"}},"metadata":{}},{"name":"stdout","text":"EVAL: [0/49] Elapsed 0m 0s (remain 0m 17s) Loss: 0.7317 \nEVAL: [20/49] Elapsed 0m 7s (remain 0m 9s) Loss: 0.6618 \nEVAL: [40/49] Elapsed 0m 13s (remain 0m 2s) Loss: 0.6527 \n","output_type":"stream"},{"name":"stderr","text":"Epoch 1 - avg_train_loss: 0.6799  avg_val_loss: 0.6496  time: 176s\nEpoch 1 - Score: 0.6709\nEpoch 1 - Save Best Score: 0.6709 Model\n","output_type":"stream"},{"name":"stdout","text":"EVAL: [48/49] Elapsed 0m 16s (remain 0m 0s) Loss: 0.6496 \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train:   0%|          | 0/72 [00:00<?, ?train_batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53ee0b1c2b694e4d9fbdfc3e0717b7c2"}},"metadata":{}},{"name":"stdout","text":"Epoch: [2][0/72] Elapsed 0m 2s (remain 2m 39s) Loss: 0.6145 Grad: 128557.2266  LR: 0.00000966  \nEpoch: [2][20/72] Elapsed 0m 46s (remain 1m 53s) Loss: 0.6272 Grad: 119459.8750  LR: 0.00000923  \nEpoch: [2][40/72] Elapsed 1m 31s (remain 1m 8s) Loss: 0.6368 Grad: 124682.0000  LR: 0.00000864  \nEpoch: [2][60/72] Elapsed 2m 15s (remain 0m 24s) Loss: 0.6407 Grad: 115865.5938  LR: 0.00000791  \nEpoch: [2][71/72] Elapsed 2m 40s (remain 0m 0s) Loss: 0.6420 Grad: 110593.0234  LR: 0.00000746  \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/49 [00:00<?, ?valid_batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c28b555bb5b2459e886920e401d7ea86"}},"metadata":{}},{"name":"stdout","text":"EVAL: [0/49] Elapsed 0m 0s (remain 0m 16s) Loss: 0.7241 \nEVAL: [20/49] Elapsed 0m 7s (remain 0m 9s) Loss: 0.6612 \nEVAL: [40/49] Elapsed 0m 13s (remain 0m 2s) Loss: 0.6500 \n","output_type":"stream"},{"name":"stderr","text":"Epoch 2 - avg_train_loss: 0.6420  avg_val_loss: 0.6455  time: 177s\nEpoch 2 - Score: 0.6578\n","output_type":"stream"},{"name":"stdout","text":"EVAL: [48/49] Elapsed 0m 16s (remain 0m 0s) Loss: 0.6455 \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train:   0%|          | 0/72 [00:00<?, ?train_batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2bae7280af24ddbab095c18ecf6b3d7"}},"metadata":{}},{"name":"stdout","text":"Epoch: [3][0/72] Elapsed 0m 2s (remain 2m 38s) Loss: 0.6113 Grad: 114959.3047  LR: 0.00000742  \nEpoch: [3][20/72] Elapsed 0m 46s (remain 1m 53s) Loss: 0.6314 Grad: 116985.4844  LR: 0.00000653  \nEpoch: [3][40/72] Elapsed 1m 31s (remain 1m 8s) Loss: 0.6357 Grad: 128626.8359  LR: 0.00000558  \nEpoch: [3][60/72] Elapsed 2m 15s (remain 0m 24s) Loss: 0.6355 Grad: 112117.7422  LR: 0.00000461  \nEpoch: [3][71/72] Elapsed 2m 39s (remain 0m 0s) Loss: 0.6333 Grad: 98323.5078  LR: 0.00000409  \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/49 [00:00<?, ?valid_batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09656970de8a4fc49fc03913c1748959"}},"metadata":{}},{"name":"stdout","text":"EVAL: [0/49] Elapsed 0m 0s (remain 0m 16s) Loss: 0.7139 \nEVAL: [20/49] Elapsed 0m 7s (remain 0m 9s) Loss: 0.6517 \nEVAL: [40/49] Elapsed 0m 13s (remain 0m 2s) Loss: 0.6411 \n","output_type":"stream"},{"name":"stderr","text":"Epoch 3 - avg_train_loss: 0.6333  avg_val_loss: 0.6372  time: 177s\nEpoch 3 - Score: 0.6422\n","output_type":"stream"},{"name":"stdout","text":"EVAL: [48/49] Elapsed 0m 16s (remain 0m 0s) Loss: 0.6372 \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train:   0%|          | 0/72 [00:00<?, ?train_batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb4b5f8e497b49e691c11e96e19faaa1"}},"metadata":{}},{"name":"stdout","text":"Epoch: [4][0/72] Elapsed 0m 2s (remain 2m 37s) Loss: 0.6110 Grad: 117373.3984  LR: 0.00000404  \nEpoch: [4][20/72] Elapsed 0m 46s (remain 1m 53s) Loss: 0.6310 Grad: 100906.6094  LR: 0.00000311  \nEpoch: [4][40/72] Elapsed 1m 31s (remain 1m 8s) Loss: 0.6321 Grad: 110194.1094  LR: 0.00000226  \nEpoch: [4][60/72] Elapsed 2m 15s (remain 0m 24s) Loss: 0.6295 Grad: 103351.2734  LR: 0.00000150  \nEpoch: [4][71/72] Elapsed 2m 40s (remain 0m 0s) Loss: 0.6287 Grad: 106216.7188  LR: 0.00000114  \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/49 [00:00<?, ?valid_batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9beda89b72d04f4a884f20f874eb63c7"}},"metadata":{}},{"name":"stdout","text":"EVAL: [0/49] Elapsed 0m 0s (remain 0m 16s) Loss: 0.7092 \nEVAL: [20/49] Elapsed 0m 7s (remain 0m 9s) Loss: 0.6498 \nEVAL: [40/49] Elapsed 0m 14s (remain 0m 2s) Loss: 0.6397 \n","output_type":"stream"},{"name":"stderr","text":"Epoch 4 - avg_train_loss: 0.6287  avg_val_loss: 0.6355  time: 177s\nEpoch 4 - Score: 0.6326\n","output_type":"stream"},{"name":"stdout","text":"EVAL: [48/49] Elapsed 0m 16s (remain 0m 0s) Loss: 0.6355 \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train:   0%|          | 0/72 [00:00<?, ?train_batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff4da8b9a8404731888ed99dcc6ca445"}},"metadata":{}},{"name":"stdout","text":"Epoch: [5][0/72] Elapsed 0m 2s (remain 2m 38s) Loss: 0.6726 Grad: 103752.4141  LR: 0.00000111  \nEpoch: [5][20/72] Elapsed 0m 46s (remain 1m 53s) Loss: 0.6231 Grad: 102149.2500  LR: 0.00000058  \nEpoch: [5][40/72] Elapsed 1m 31s (remain 1m 8s) Loss: 0.6310 Grad: 96357.3047  LR: 0.00000021  \nEpoch: [5][60/72] Elapsed 2m 15s (remain 0m 24s) Loss: 0.6280 Grad: 101141.3672  LR: 0.00000003  \nEpoch: [5][71/72] Elapsed 2m 40s (remain 0m 0s) Loss: 0.6294 Grad: 103610.9844  LR: 0.00000000  \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/49 [00:00<?, ?valid_batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"317be9c0a0004ae1b6367b8797a5ca7f"}},"metadata":{}},{"name":"stdout","text":"EVAL: [0/49] Elapsed 0m 0s (remain 0m 17s) Loss: 0.7162 \nEVAL: [20/49] Elapsed 0m 7s (remain 0m 9s) Loss: 0.6568 \nEVAL: [40/49] Elapsed 0m 13s (remain 0m 2s) Loss: 0.6462 \n","output_type":"stream"},{"name":"stderr","text":"Epoch 5 - avg_train_loss: 0.6294  avg_val_loss: 0.6423  time: 177s\nEpoch 5 - Score: 0.6322\n","output_type":"stream"},{"name":"stdout","text":"EVAL: [48/49] Elapsed 0m 16s (remain 0m 0s) Loss: 0.6423 \n","output_type":"stream"},{"name":"stderr","text":"Score: 0.6709\n========== CV ==========\nScore: 0.6709\n","output_type":"stream"}]},{"cell_type":"code","source":"oof_df[\"preds\"] = oof_df[\"preds\"].apply(lambda x: sigmoid(x))\noof_df","metadata":{"execution":{"iopub.status.busy":"2023-12-28T17:43:07.964145Z","iopub.execute_input":"2023-12-28T17:43:07.964583Z","iopub.status.idle":"2023-12-28T17:43:07.984707Z","shell.execute_reply.started":"2023-12-28T17:43:07.964550Z","shell.execute_reply":"2023-12-28T17:43:07.983647Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"                id                                               text  generated     preds\n0     EC35456D4E07  Conserve energy and resources,some businesses ...          0  0.635946\n1     638D7F913AAB  Do you think the greatest accomplishment in th...          1  0.602844\n2     EBE636368EBC  People make there own decisions because they d...          1  0.651876\n3     B4B82E063D04  is setting an good example by your own behavio...          1  0.587057\n4     C1314085435C  I agree with Ralph waldo Emerson because he sa...          0  0.686414\n...            ...                                                ...        ...       ...\n1550  7ACF284A8B7C  I think that work in groups is more benefit. B...          0  0.678539\n1551  71F12F9F01DE  I agree with this prompt many cases it is impo...          1  0.620143\n1552  DF149975C610  I agree with emerson's statement. I will grow ...          1  0.656847\n1553  F0B44890C961  Dear Sir or Madam:Yes school should control st...          1  0.635581\n1554  80CCEFCCD166  Some may say that working in a group is better...          1  0.625627\n\n[1555 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n      <th>generated</th>\n      <th>preds</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>EC35456D4E07</td>\n      <td>Conserve energy and resources,some businesses ...</td>\n      <td>0</td>\n      <td>0.635946</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>638D7F913AAB</td>\n      <td>Do you think the greatest accomplishment in th...</td>\n      <td>1</td>\n      <td>0.602844</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>EBE636368EBC</td>\n      <td>People make there own decisions because they d...</td>\n      <td>1</td>\n      <td>0.651876</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>B4B82E063D04</td>\n      <td>is setting an good example by your own behavio...</td>\n      <td>1</td>\n      <td>0.587057</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>C1314085435C</td>\n      <td>I agree with Ralph waldo Emerson because he sa...</td>\n      <td>0</td>\n      <td>0.686414</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1550</th>\n      <td>7ACF284A8B7C</td>\n      <td>I think that work in groups is more benefit. B...</td>\n      <td>0</td>\n      <td>0.678539</td>\n    </tr>\n    <tr>\n      <th>1551</th>\n      <td>71F12F9F01DE</td>\n      <td>I agree with this prompt many cases it is impo...</td>\n      <td>1</td>\n      <td>0.620143</td>\n    </tr>\n    <tr>\n      <th>1552</th>\n      <td>DF149975C610</td>\n      <td>I agree with emerson's statement. I will grow ...</td>\n      <td>1</td>\n      <td>0.656847</td>\n    </tr>\n    <tr>\n      <th>1553</th>\n      <td>F0B44890C961</td>\n      <td>Dear Sir or Madam:Yes school should control st...</td>\n      <td>1</td>\n      <td>0.635581</td>\n    </tr>\n    <tr>\n      <th>1554</th>\n      <td>80CCEFCCD166</td>\n      <td>Some may say that working in a group is better...</td>\n      <td>1</td>\n      <td>0.625627</td>\n    </tr>\n  </tbody>\n</table>\n<p>1555 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### <b><span style='color:#F1A424'>Confusion Matrix</span></b>\n","metadata":{}},{"cell_type":"code","source":"torch.save(model.state_dict(), '/kaggle/working/output/custom_model_state_dict.pt')\ntorch.save(model.config, '/kaggle/working/output/model_config.pth')\n","metadata":{"execution":{"iopub.status.busy":"2023-12-28T17:43:12.908614Z","iopub.execute_input":"2023-12-28T17:43:12.909313Z","iopub.status.idle":"2023-12-28T17:43:13.805671Z","shell.execute_reply.started":"2023-12-28T17:43:12.909279Z","shell.execute_reply":"2023-12-28T17:43:13.804403Z"},"trusted":true},"execution_count":19,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(\u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/working/output/custom_model_state_dict.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(model\u001b[38;5;241m.\u001b[39mconfig, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/working/output/model_config.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"],"ename":"NameError","evalue":"name 'model' is not defined","output_type":"error"}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\n\nfrom sklearn.metrics import confusion_matrix\n\ndef binarize(x, threshold):\n    if x > threshold:\n        x = 1\n    else:\n        x = 0\n    return x\n\n# Assuming df is your pandas DataFrame\noof_df[\"binary\"] = oof_df[\"preds\"].apply(lambda x: binarize(x, 0.5))\ntrue_labels = oof_df[\"generated\"].values\npredicted_labels = oof_df[\"binary\"].values\n\n# Get the unique classes from both true and predicted labels\nclasses = np.unique(np.concatenate((true_labels, predicted_labels)))\n\n# Compute the confusion matrix\ncm = confusion_matrix(true_labels, predicted_labels, labels=classes)\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=classes, yticklabels=classes)\nplt.xlabel(\"Predicted Labels\")\nplt.ylabel(\"True Labels\")\nplt.title(\"Confusion Matrix\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!zip -r output.zip /kaggle/working/output","metadata":{"execution":{"iopub.status.busy":"2023-12-28T17:44:01.366854Z","iopub.execute_input":"2023-12-28T17:44:01.367232Z","iopub.status.idle":"2023-12-28T17:44:16.686079Z","shell.execute_reply.started":"2023-12-28T17:44:01.367203Z","shell.execute_reply":"2023-12-28T17:44:16.684752Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"  adding: kaggle/working/output/ (stored 0%)\n  adding: kaggle/working/output/tokenizer/ (stored 0%)\n  adding: kaggle/working/output/tokenizer/special_tokens_map.json (deflated 42%)\n  adding: kaggle/working/output/tokenizer/tokenizer_config.json (deflated 43%)\n  adding: kaggle/working/output/tokenizer/vocab.txt (deflated 53%)\n  adding: kaggle/working/output/tokenizer/tokenizer.json (deflated 71%)\n  adding: kaggle/working/output/distilbert-base-uncased_best.pth (deflated 8%)\n  adding: kaggle/working/output/config.pth (deflated 48%)\n  adding: kaggle/working/output/oof_df.csv (deflated 68%)\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}